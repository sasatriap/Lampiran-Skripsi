{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasatriap/Lampiran-Skripsi/blob/main/SC_Rasio_90_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TkZLoQm474BX"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBGG7RBI74Bk"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 1. PENGUMPULAN DATA\n",
        "#-----------------------------------------------------------\n",
        "print(\"=== 1. PENGUMPULAN DATA ===\")\n",
        "# Load dataset\n",
        "file_path = 'C:/Users/Want To Sell/Documents/Kuliah/SKRIPSI/sistem percobaan/cobadata2.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "print(f\"Dataset berhasil dimuat. Jumlah data: {data.shape[0]} baris, {data.shape[1]} kolom\")\n",
        "print(\"Kolom dalam dataset:\", list(data.columns))\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuz0eZDM74Bn"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 2. DATA PREPROCESSING\n",
        "#-----------------------------------------------------------\n",
        "print(\"\\n=== 2. DATA PREPROCESSING ===\")\n",
        "\n",
        "# Pengecekan missing value\n",
        "print(\"\\n--- Pengecekan Missing Value ---\")\n",
        "missing_summary = data.isnull().sum()\n",
        "print(missing_summary)\n",
        "\n",
        "# Menghapus baris dengan missing value jika ada\n",
        "if missing_summary.any():\n",
        "    print(\"\\nData memiliki missing value. Menghapus baris dengan nilai kosong...\")\n",
        "    data = data.dropna()\n",
        "    print(f\"Missing value telah dihapus. Data sekarang: {data.shape[0]} baris\")\n",
        "else:\n",
        "    print(\"\\nData tidak memiliki missing value.\")\n",
        "\n",
        "# Menampilkan data sebelum encoding\n",
        "print(\"\\n--- Data Sebelum Label Encoding ---\")\n",
        "print(data.head())\n",
        "\n",
        "# Inisialisasi LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Daftar kolom kategorikal\n",
        "categorical_columns = ['usia', 'pendidikan', 'jenis_kelamin', 'pekerjaan',\n",
        "                      'alasan_mengunjungi', 'kedatangan_kembali']\n",
        "\n",
        "# Dictionary untuk menyimpan hasil mapping encoding\n",
        "label_mappings = {}\n",
        "\n",
        "# Proses Label Encoding\n",
        "for col in categorical_columns:\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    # Simpan mapping label\n",
        "    label_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "\n",
        "print(\"\\n--- Data Setelah Label Encoding ---\")\n",
        "print(data.head())\n",
        "\n",
        "# Menampilkan hasil mapping label encoding untuk tiap kolom\n",
        "print(\"\\n=== Mapping Label Encoding ===\")\n",
        "for col, mapping in label_mappings.items():\n",
        "    print(f\"\\nMapping untuk '{col}':\")\n",
        "    for category, encoded_value in mapping.items():\n",
        "        print(f\"  {category} -> {encoded_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHiSB_MD74Bq"
      },
      "outputs": [],
      "source": [
        "# Memisahkan fitur dan target\n",
        "X = data.iloc[:, :-1]  # Semua kolom kecuali kolom terakhir\n",
        "y = data.iloc[:, -1]   # Kolom terakhir sebagai target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_lwCeOk74Bs"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 3. SMOTE (SYNTHETIC MINORITY OVERSAMPLING TECHNIQUE)\n",
        "#-----------------------------------------------------------\n",
        "print(\"\\n=== 3. SMOTE ===\")\n",
        "print(\"Distribusi kelas sebelum SMOTE:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Mendapatkan jumlah total data sebelum SMOTE\n",
        "total_before = len(y)\n",
        "class_counts_before = y.value_counts()\n",
        "percent_before = (class_counts_before / total_before) * 100\n",
        "\n",
        "# Visualisasi distribusi kelas sebelum SMOTE\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x=class_counts_before.index, y=class_counts_before.values, hue=class_counts_before.index,\n",
        "            palette=\"coolwarm\", legend=False)\n",
        "plt.title(\"Distribusi Kelas Sebelum SMOTE\", fontsize=14, fontweight=\"bold\", color=\"darkred\")\n",
        "plt.xlabel(\"Kelas\", fontsize=12, fontweight=\"bold\", color=\"black\")\n",
        "plt.ylabel(\"Jumlah Sampel\", fontsize=12, fontweight=\"bold\", color=\"black\")\n",
        "plt.xticks(ticks=[0, 1, 2], labels=[\"Iya (0)\", \"Netral (1)\", \"Tidak (2)\"], fontsize=11, color=\"black\")\n",
        "\n",
        "# Menambahkan label presentase\n",
        "for i, value in enumerate(class_counts_before.values):\n",
        "    plt.text(i, value + 5, f\"{percent_before.iloc[i]:.2f}%\", ha='center', fontsize=10, fontweight=\"bold\", color=\"black\")\n",
        "\n",
        "# Menerapkan SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nDistribusi kelas setelah SMOTE:\")\n",
        "print(y_resampled.value_counts())\n",
        "\n",
        "# Mendapatkan jumlah total data setelah SMOTE\n",
        "total_after = len(y_resampled)\n",
        "class_counts_after = y_resampled.value_counts()\n",
        "percent_after = (class_counts_after / total_after) * 100\n",
        "\n",
        "# Visualisasi distribusi kelas setelah SMOTE\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x=class_counts_after.index, y=class_counts_after.values, hue=class_counts_after.index,\n",
        "            palette=\"coolwarm\", legend=False)\n",
        "plt.title(\"Distribusi Kelas Setelah SMOTE\", fontsize=14, fontweight=\"bold\", color=\"darkgreen\")\n",
        "plt.xlabel(\"Kelas\", fontsize=12, fontweight=\"bold\", color=\"black\")\n",
        "plt.ylabel(\"Jumlah Sampel\", fontsize=12, fontweight=\"bold\", color=\"black\")\n",
        "plt.xticks(ticks=[0, 1, 2], labels=[\"Iya (0)\", \"Netral (1)\", \"Tidak (2)\"], fontsize=11, color=\"black\")\n",
        "\n",
        "# Menambahkan label presentase\n",
        "for i, value in enumerate(class_counts_after.values):\n",
        "    plt.text(i, value + 5, f\"{percent_after.iloc[i]:.2f}%\", ha='center', fontsize=10, fontweight=\"bold\", color=\"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jnOqoFM74Bu"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 4. SELEKSI FITUR CHI-SQUARE\n",
        "#-----------------------------------------------------------\n",
        "print(\"\\n=== 4. SELEKSI FITUR CHI-SQUARE ===\")\n",
        "\n",
        "# Menghitung Chi-Square Score\n",
        "print(\"Perhitungan Chi-Square Score\")\n",
        "chi_scores, _ = chi2(X_resampled, y_resampled)\n",
        "feature_scores = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Chi-Square Score': chi_scores\n",
        "})\n",
        "\n",
        "# Mengurutkan fitur berdasarkan Chi-Square Score\n",
        "print(\"\\nChi-Square Score untuk setiap fitur:\")\n",
        "feature_scores_sorted = feature_scores.sort_values(by='Chi-Square Score', ascending=False)\n",
        "print(\"Fitur diurutkan berdasarkan Chi-Square Score (dari tertinggi):\")\n",
        "print(feature_scores_sorted)\n",
        "\n",
        "# Penerapan Cutoff Persentase pada Semua Fitur\n",
        "print(\"\\n--- Penerapan Cutoff Persentase pada Fitur ---\")\n",
        "cutoff_percentages = [0.25, 0.50, 0.75, 1.0]\n",
        "feature_sets = {}  # Untuk menyimpan fitur-fitur terpilih untuk setiap cutoff\n",
        "\n",
        "for cutoff in cutoff_percentages:\n",
        "    n_features = max(1, int(len(X.columns) * cutoff))  # Minimal 1 fitur\n",
        "    selected_features = feature_scores_sorted['Feature'].head(n_features).tolist()\n",
        "\n",
        "    feature_sets[f\"top_{int(cutoff * 100)}pct\"] = selected_features\n",
        "\n",
        "    print(f\"\\nCutoff {cutoff*100}% menghasilkan {n_features} fitur:\")\n",
        "    for i, feature in enumerate(selected_features, 1):\n",
        "        chi_score = feature_scores_sorted.loc[\n",
        "            feature_scores_sorted['Feature'] == feature, 'Chi-Square Score'\n",
        "        ].values[0]\n",
        "        print(f\"{i}. {feature} (Chi-Square: {chi_score:.4f})\")\n",
        "\n",
        "# 4.4 Visualisasi Hasil Seleksi Fitur\n",
        "print(\"\\n--- Visualisasi Hasil Seleksi Fitur ---\")\n",
        "# Visualisasi Chi-Square Scores untuk semua fitur\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Feature', y='Chi-Square Score', data=feature_scores_sorted)\n",
        "plt.title('Chi-Square Scores of All Features')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFb-BSoy74Bv"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 5. SPLITTING DATA\n",
        "#-----------------------------------------------------------\n",
        "print(\"\\n=== 5. SPLITTING DATA ===\")\n",
        "# Membagi dataset menjadi data training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Jumlah data training: {X_train.shape[0]} sampel\")\n",
        "print(f\"Jumlah data testing: {X_test.shape[0]} sampel\")\n",
        "print(f\"Rasio pembagian: {X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]):.2f} : {X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]):.2f}\")\n",
        "\n",
        "# Menampilkan distribusi kelas pada data training\n",
        "train_counts = np.bincount(y_train)\n",
        "print(\"\\nDistribusi kelas pada data training:\")\n",
        "print(f\"Iya (0): {train_counts[0]} sampel ({train_counts[0]/len(y_train):.2f})\")\n",
        "print(f\"Netral (1): {train_counts[1]} sampel ({train_counts[1]/len(y_train):.2f})\")\n",
        "print(f\"Tidak (2): {train_counts[2]} sampel ({train_counts[2]/len(y_train):.2f})\")\n",
        "\n",
        "# Menampilkan distribusi kelas pada data testing\n",
        "test_counts = np.bincount(y_test)\n",
        "print(\"\\nDistribusi kelas pada data testing:\")\n",
        "print(f\"Iya (0): {test_counts[0]} sampel ({test_counts[0]/len(y_test):.2f})\")\n",
        "print(f\"Netral (1): {test_counts[1]} sampel ({test_counts[1]/len(y_test):.2f})\")\n",
        "print(f\"Tidak (2): {test_counts[2]} sampel ({test_counts[2]/len(y_test):.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kplovQ0l74Bx"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 6. KLASIFIKASI\n",
        "#-----------------------------------------------------------\n",
        "print(\"=== 6. KLASIFIKASI KNN, RANDOM FOREST, XGBOOST ===\")\n",
        "\n",
        "# X_train_features: Fitur (independen) dari data pelatihan\n",
        "# X_test_features: Fitur dari data pengujian\n",
        "# y_train: Label/target dari data pelatihan\n",
        "# y_test: Label/target dari data pengujian\n",
        "# feature_set_name: Nama atau label dari set fitur yang digunakan (misalnya: 'top_50pct')\n",
        "\n",
        "# Fungsi evaluate model digunakan untuk menerima input\n",
        "def evaluate_model(X_train_features, X_test_features, y_train, y_test, feature_set_name):\n",
        "\n",
        "    # Inisialisasi tiga model klasifikasi: K-NN, Random Forest, dan XGBoost\n",
        "    models = {\n",
        "        'K-NN': KNeighborsClassifier(),\n",
        "        'Random Forest': RandomForestClassifier(random_state=42),\n",
        "        'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "    }\n",
        "\n",
        "    # results: Dictionary untuk menyimpan hasil klasifikasi tiap model\n",
        "    results = {}\n",
        "\n",
        "    # Melakukan pelatihan dan evaluasi pada setiap model\n",
        "    for name, model in models.items():\n",
        "        # Melatih model menggunakan data training\n",
        "        model.fit(X_train_features, y_train)\n",
        "\n",
        "        # Melakukan prediksi terhadap data testing\n",
        "        y_pred = model.predict(X_test_features)\n",
        "\n",
        "        # accuracy: Nilai akurasi dari model (dalam persen)\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "        # conf_matrix: Matriks konfusi dari hasil prediksi\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # class_counts: Jumlah prediksi per kelas dari hasil y_pred\n",
        "        class_counts = Counter(y_pred)\n",
        "        sorted_counts = {key: class_counts[key] for key in sorted(class_counts)}\n",
        "\n",
        "        # Menyimpan semua hasil ke dalam dictionary untuk model saat ini\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'predictions': y_pred,\n",
        "            'conf_matrix': conf_matrix\n",
        "        }\n",
        "\n",
        "        # Menampilkan informasi hasil evaluasi di terminal\n",
        "        print(f\"\\nModel: {name}\")\n",
        "        print(f\"Akurasi: {accuracy:.2f}%\")\n",
        "        print(f\"Jumlah prediksi per kelas (0, 1, 2): {sorted_counts}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # Visualisasi confusion matrix menggunakan heatmap\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        cmap_choice = \"Blues\" if name == \"K-NN\" else \"Greens\" if name == \"Random Forest\" else \"Reds\"\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap=cmap_choice,\n",
        "            xticklabels=['Iya', 'Netral', 'Tidak'], yticklabels=['Iya', 'Netral', 'Tidak']\n",
        "        )\n",
        "        plt.title(f\"Confusion Matrix - {name} ({feature_set_name})\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.show()\n",
        "\n",
        "    # Mengembalikan hasil evaluasi seluruh model\n",
        "    return results\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Menjalankan evaluasi untuk setiap set fitur yang telah dipilih sebelumnya\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# all_results: Dictionary untuk menyimpan hasil klasifikasi dari tiap kombinasi fitur dan model\n",
        "all_results = {}\n",
        "\n",
        "# Melakukan iterasi untuk setiap kombinasi fitur berdasarkan nama cut-off (misalnya: 25%, 50%, 75%, 100%)\n",
        "for cutoff_name, selected_features in feature_sets.items():\n",
        "    # Memilih fitur tertentu dari data training dan testing sesuai dengan cut-off saat ini\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    # Memanggil fungsi evaluate model untuk set fitur ini dan menyimpan dalam eval_results\n",
        "    all_results[cutoff_name] = evaluate_model(\n",
        "        X_train_selected, X_test_selected, y_train, y_test, cutoff_name\n",
        "    )\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Menentukan model terbaik dari seluruh hasil klasifikasi\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "# best_model: Menyimpan nama algoritma terbaik (berdasarkan akurasi tertinggi)\n",
        "# best_accuracy: Menyimpan nilai akurasi tertinggi yang ditemukan\n",
        "# best_cutoff: Menyimpan nama set fitur (cut-off presentase) yang menghasilkan model terbaik\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "best_cutoff = None\n",
        "\n",
        "# Loop untuk mencari model dengan akurasi tertinggi dari seluruh kombinasi\n",
        "for cutoff_name, results in all_results.items():\n",
        "    for model_name, model_results in results.items():\n",
        "        if model_results['accuracy'] > best_accuracy:\n",
        "            best_accuracy = model_results['accuracy']\n",
        "            best_model = model_name\n",
        "            best_cutoff = cutoff_name\n",
        "\n",
        "# Menampilkan hasil akhir berupa model terbaik dengan akurasi tertinggi\n",
        "print(f\"\\nModel terbaik: {best_model} dengan fitur {best_cutoff}, Akurasi: {best_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDGLVL5y74B0"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------\n",
        "# 7. ANALASIS FAKTOR KELOMPOK USIA\n",
        "#-----------------------------------------------------------\n",
        "print(\"\\n=== 7.ANALISIS FAKTOR BERDASARKAN KELOMPOK USIA ===\")\n",
        "\n",
        "def analisis_faktor_per_usia(data, encoders):\n",
        "    # Reverse mapping untuk kategori\n",
        "    kedatangan_reverse = {v: k for k, v in encoders['kedatangan_kembali'].items()}\n",
        "    usia_reverse = {v: k for k, v in encoders['usia'].items()}\n",
        "\n",
        "    # Pilih kolom fitur (kecuali usia & kedatangan_kembali)\n",
        "    feature_columns = [col for col in data.columns if col not in ['usia', 'kedatangan_kembali']]\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    for i, (usia_code, usia_label) in enumerate(usia_reverse.items(), start=1):\n",
        "        print(f\"\\n--- Kelompok Usia: {usia_label} ---\")\n",
        "\n",
        "        # Filter data per kelompok usia\n",
        "        subset = data[data['usia'] == usia_code]\n",
        "        X, y = subset[feature_columns], subset['kedatangan_kembali']\n",
        "\n",
        "        print(f\"Jumlah sampel: {len(X)}\")\n",
        "        print(\"Distribusi Kedatangan Kembali:\")\n",
        "        print(y.value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
        "\n",
        "        # Latih Random Forest\n",
        "        model = RandomForestClassifier(random_state=42)\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # Ambil 10 fitur terpenting\n",
        "        feat_importance = pd.DataFrame({\n",
        "            'Feature': feature_columns,\n",
        "            'Importance': model.feature_importances_\n",
        "        }).nlargest(10, 'Importance')\n",
        "\n",
        "        print(\"\\nTop 10 Faktor yang Mempengaruhi Kedatangan Kembali:\")\n",
        "        print(feat_importance.to_string(index=False))\n",
        "\n",
        "        # Plot hasil\n",
        "        plt.subplot(3, 1, i)\n",
        "        sns.barplot(x='Importance', y='Feature', data=feat_importance, palette='viridis')\n",
        "        plt.title(f'Faktor Penting - Usia: {usia_label}', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Faktor yang Mempengaruhi Kedatangan Kembali Berdasarkan Usia',\n",
        "                 fontsize=14, fontweight='bold', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "# Panggil fungsi analisis\n",
        "analisis_faktor_per_usia(data, label_mappings)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}